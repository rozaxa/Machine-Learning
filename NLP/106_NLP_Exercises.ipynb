{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Exercises\n",
    "\n",
    "We have five exercises in this section. The exercises are:\n",
    "1. Build your own tokenizer, where you need to implement two functions to implement a tokenizer based on regular expression.\n",
    "2. Get tags from Trump speech.\n",
    "3. Get the nouns in the last 10 sentences from Trump's speech and find the nouns divided by sentencens. Use SpaCy.\n",
    "4. Build your own Bag Of Words implementation using tokenizer created before.\n",
    "5. Build a 5-gram model and clean up the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Build your own tokenizer\n",
    "\n",
    "Build two different tokenizers:\n",
    "- ``tokenize_sentence``: function tokenizing text into sentences,\n",
    "- ``tokenize_word``: function tokenizing text into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:14:50.619702Z",
     "start_time": "2024-05-23T10:14:50.611956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentences:\n",
      "['Here we go again.', 'I was supposed to add this text later.', \"Well, it's 10.p.m. here, and I'm actually having fun making this course.\", ':oI hope you are getting along fine with this presentation, I really did try.', 'And one last sentence, just so you can test you tokenizers better.']\n",
      "Tokenized words:\n",
      "['Here', 'we', 'go', 'again.', 'I', 'was', 'supposed', 'to', 'add', 'this', 'text', 'later.', 'Well,', \"it's\", '10.p.m.', 'here,', 'and', \"I'm\", 'actually', 'having', 'fun', 'making', 'this', 'course.', ':oI', 'hope', 'you', 'are', 'getting', 'along', 'fine', 'with', 'this', 'presentation,', 'I', 'really', 'did', 'try.', 'And', 'one', 'last', 'sentence,', 'just', 'so', 'you', 'can', 'test', 'you', 'tokenizers', 'better.']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import re\n",
    "\n",
    "\n",
    "def tokenize_words(text: str) -> list:\n",
    "    \"\"\"Tokenize text into words using regex.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "            Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "            List containing words tokenized from text\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = \"\\\\s+\"\n",
    "    words = re.split(pattern, text)\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_sentence(text: str) -> list:\n",
    "    \"\"\"Tokenize text into words using regex.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "            Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "            List containing words tokenized from text\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = r'(?<!\\w\\.\\w.)(?<![A-Z]\\.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?) '\n",
    "    sentence = re.split(pattern,text)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "text = \"Here we go again. I was supposed to add this text later. \\\n",
    "Well, it's 10.p.m. here, and I'm actually having fun making this course. :o\\\n",
    "I hope you are getting along fine with this presentation, I really did try. \\\n",
    "And one last sentence, just so you can test you tokenizers better.\"\n",
    "\n",
    "print(\"Tokenized sentences:\")\n",
    "print(tokenize_sentence(text))\n",
    "\n",
    "print(\"Tokenized words:\")\n",
    "print(tokenize_words(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. Get tags from Trump speech using NLTK\n",
    "\n",
    "You should use the ``trump.txt`` file, read it and find the tags for each word. Use NLTK for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('very', 'RB'),\n",
       " ('much', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Speaker', 'NNP'),\n",
       " (',', ','),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Vice', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " (',', ','),\n",
       " ('Members', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Congress', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('First', 'NNP'),\n",
       " ('Lady', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('citizens', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('America', 'NNP'),\n",
       " (':', ':'),\n",
       " ('Tonight', 'NN'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('mark', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('conclusion', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('celebration', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Black', 'NNP'),\n",
       " ('History', 'NNP'),\n",
       " ('Month', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('reminded', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('Nation', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('path', 'NN'),\n",
       " ('towards', 'NNS'),\n",
       " ('civil', 'JJ'),\n",
       " ('rights', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('work', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('still', 'RB'),\n",
       " ('remains', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('done', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('Recent', 'JJ'),\n",
       " ('threats', 'NNS'),\n",
       " ('targeting', 'VBG'),\n",
       " ('Jewish', 'NNP'),\n",
       " ('community', 'NN'),\n",
       " ('centers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('vandalism', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Jewish', 'JJ'),\n",
       " ('cemeteries', 'NNS'),\n",
       " (',', ','),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('last', 'JJ'),\n",
       " ('week', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('shooting', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Kansas', 'NNP'),\n",
       " ('City', 'NNP'),\n",
       " (',', ','),\n",
       " ('remind', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('that', 'IN'),\n",
       " ('while', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('nation', 'NN'),\n",
       " ('divided', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('policies', 'NNS'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('country', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('stands', 'VBZ'),\n",
       " ('united', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('condemning', 'VBG'),\n",
       " ('hate', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('evil', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('very', 'RB'),\n",
       " ('ugly', 'RB'),\n",
       " ('forms', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Each', 'DT'),\n",
       " ('American', 'JJ'),\n",
       " ('generation', 'NN'),\n",
       " ('passes', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('torch', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('truth', 'NN'),\n",
       " (',', ','),\n",
       " ('liberty', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('justice', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('unbroken', 'JJ'),\n",
       " ('chain', 'NN'),\n",
       " (',', ','),\n",
       " ('all', 'PDT'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('down', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('present', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('That', 'DT'),\n",
       " ('torch', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('now', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('hands', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('use', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('light', 'VB'),\n",
       " ('up', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('here', 'RB'),\n",
       " ('tonight', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('deliver', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('message', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('unity', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('strength', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('message', 'NN'),\n",
       " ('deeply', 'RB'),\n",
       " ('delivered', 'VBN'),\n",
       " ('from', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('heart', 'NN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('chapter', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('American', 'JJ'),\n",
       " ('greatness', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('now', 'RB'),\n",
       " ('beginning', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('A', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('national', 'JJ'),\n",
       " ('pride', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('sweeping', 'VBG'),\n",
       " ('across', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('Nation', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('surge', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('optimism', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('placing', 'VBG'),\n",
       " ('impossible', 'JJ'),\n",
       " ('dreams', 'NNS'),\n",
       " ('firmly', 'RB'),\n",
       " ('within', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('grasp', 'NN'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('witnessing', 'VBG'),\n",
       " ('today', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('renewal', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('American', 'JJ'),\n",
       " ('spirit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Our', 'PRP$'),\n",
       " ('allies', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('find', 'VB'),\n",
       " ('that', 'DT'),\n",
       " ('America', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('once', 'RB'),\n",
       " ('again', 'RB'),\n",
       " ('ready', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('lead', 'VB'),\n",
       " ('.', '.'),\n",
       " ('All', 'PDT'),\n",
       " ('the', 'DT'),\n",
       " ('nations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world—friend', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('foe—will', 'VB'),\n",
       " ('find', 'VB'),\n",
       " ('that', 'DT'),\n",
       " ('America', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('strong', 'JJ'),\n",
       " (',', ','),\n",
       " ('America', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('proud', 'JJ'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('America', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('free', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('9', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('will', 'MD'),\n",
       " ('celebrate', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('250th', 'JJ'),\n",
       " ('anniversary', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('founding', 'NN'),\n",
       " (':', ':'),\n",
       " ('250', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('since', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('declared', 'VBD'),\n",
       " ('our', 'PRP$'),\n",
       " ('independence', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('milestones', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('history', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('what', 'WP'),\n",
       " ('will', 'MD'),\n",
       " ('America', 'NNP'),\n",
       " ('look', 'VB'),\n",
       " ('like', 'IN'),\n",
       " ('as', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('reach', 'VBP'),\n",
       " ('our', 'PRP$'),\n",
       " ('250th', 'CD'),\n",
       " ('year', 'NN'),\n",
       " ('?', '.'),\n",
       " ('What', 'WP'),\n",
       " ('kind', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('country', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('we', 'PRP'),\n",
       " ('leave', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('children', 'NNS'),\n",
       " ('?', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('allow', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('mistakes', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('recent', 'JJ'),\n",
       " ('decades', 'NNS'),\n",
       " ('past', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('define', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('course', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('future', 'NN'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('too', 'RB'),\n",
       " ('long', 'RB'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('watched', 'VBN'),\n",
       " ('our', 'PRP$'),\n",
       " ('middle', 'JJ'),\n",
       " ('class', 'NN'),\n",
       " ('shrink', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('exported', 'VBN'),\n",
       " ('our', 'PRP$'),\n",
       " ('jobs', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('wealth', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('foreign', 'JJ'),\n",
       " ('countries', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('financed', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('built', 'VBN'),\n",
       " ('one', 'CD'),\n",
       " ('global', 'JJ'),\n",
       " ('project', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('another', 'DT'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('ignored', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('fates', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('children', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('inner', 'JJ'),\n",
       " ('cities', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " (',', ','),\n",
       " ('Baltimore', 'NNP'),\n",
       " (',', ','),\n",
       " ('Detroit', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('other', 'JJ'),\n",
       " ('places', 'NNS'),\n",
       " ('throughout', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('land', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('defended', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('borders', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('other', 'JJ'),\n",
       " ('nations', 'NNS'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('leaving', 'VBG'),\n",
       " ('our', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('borders', 'NNS'),\n",
       " ('wide', 'JJ'),\n",
       " ('open', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('anyone', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('cross', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('for', 'IN'),\n",
       " ('drugs', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('pour', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('now', 'RB'),\n",
       " ('unprecedented', 'JJ'),\n",
       " ('rate', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('spent', 'VBN'),\n",
       " ('trillions', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('trillions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('dollars', 'NNS'),\n",
       " ('overseas', 'RB'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('infrastructure', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('home', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('so', 'RB'),\n",
       " ('badly', 'RB'),\n",
       " ('crumbled', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('Then', 'RB'),\n",
       " (',', ','),\n",
       " ('in', 'IN'),\n",
       " ('2016', 'CD'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('Earth', 'NNP'),\n",
       " ('shifted', 'VBD'),\n",
       " ('beneath', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('feet', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('rebellion', 'NN'),\n",
       " ('started', 'VBD'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('quiet', 'JJ'),\n",
       " ('protest', 'NN'),\n",
       " (',', ','),\n",
       " ('spoken', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('families', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('colors', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('creeds', 'NNS'),\n",
       " (',', ','),\n",
       " ('families', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('just', 'RB'),\n",
       " ('wanted', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('fair', 'JJ'),\n",
       " ('shot', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('children', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('fair', 'JJ'),\n",
       " ('hearing', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('concerns', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('quiet', 'JJ'),\n",
       " ('voices', 'NNS'),\n",
       " ('became', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('loud', 'JJ'),\n",
       " ('chorus', 'NN'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('citizens', 'NNS'),\n",
       " ('now', 'RB'),\n",
       " ('spoke', 'VBP'),\n",
       " ('out', 'RP'),\n",
       " ('together', 'RB'),\n",
       " (',', ','),\n",
       " ('from', 'IN'),\n",
       " ('cities', 'NNS'),\n",
       " ('small', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('large', 'JJ'),\n",
       " (',', ','),\n",
       " ('all', 'DT'),\n",
       " ('across', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('country', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Finally', 'RB'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('chorus', 'NN'),\n",
       " ('became', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('earthquake', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('turned', 'VBD'),\n",
       " ('out', 'RP'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('tens', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('millions', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('all', 'DT'),\n",
       " ('united', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('very', 'RB'),\n",
       " ('simple', 'JJ'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('crucial', 'JJ'),\n",
       " ('demand', 'NN'),\n",
       " (':', ':'),\n",
       " ('that', 'DT'),\n",
       " ('America', 'NNP'),\n",
       " ('must', 'MD'),\n",
       " ('put', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('citizens', 'NNS'),\n",
       " ('first', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Because', 'IN'),\n",
       " ('only', 'RB'),\n",
       " ('then', 'RB'),\n",
       " ('can', 'MD'),\n",
       " ('we', 'PRP'),\n",
       " ('truly', 'RB'),\n",
       " ('make', 'VBP'),\n",
       " ('America', 'NNP'),\n",
       " ('great', 'JJ'),\n",
       " ('again', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Dying', 'VBG'),\n",
       " ('industries', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('come', 'VB'),\n",
       " ('roaring', 'VBG'),\n",
       " ('back', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('life', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Heroic', 'NNP'),\n",
       " ('veterans', 'NNPS'),\n",
       " ('will', 'MD'),\n",
       " ('get', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('care', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('so', 'RB'),\n",
       " ('desperately', 'RB'),\n",
       " ('need', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Our', 'PRP$'),\n",
       " ('military', 'JJ'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('given', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('resources', 'NNS'),\n",
       " ('its', 'PRP$'),\n",
       " ('brave', 'JJ'),\n",
       " ('warriors', 'NNS'),\n",
       " ('so', 'RB'),\n",
       " ('richly', 'RB'),\n",
       " ('deserve', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Crumbling', 'VBG'),\n",
       " ('infrastructure', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('replaced', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('new', 'JJ'),\n",
       " ('roads', 'NNS'),\n",
       " (',', ','),\n",
       " ('bridges', 'NNS'),\n",
       " (',', ','),\n",
       " ('tunnels', 'NNS'),\n",
       " (',', ','),\n",
       " ('airports', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('railways', 'NNS'),\n",
       " ('gleaming', 'VBG'),\n",
       " ('across', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('very', 'RB'),\n",
       " (',', ','),\n",
       " ('very', 'RB'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('land', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Our', 'PRP$'),\n",
       " ('terrible', 'JJ'),\n",
       " ('drug', 'NN'),\n",
       " ('epidemic', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('slow', 'VB'),\n",
       " ('down', 'RB'),\n",
       " ('and', 'CC'),\n",
       " (',', ','),\n",
       " ('ultimately', 'RB'),\n",
       " (',', ','),\n",
       " ('stop', 'VB'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('our', 'PRP$'),\n",
       " ('neglected', 'JJ'),\n",
       " ('inner', 'JJ'),\n",
       " ('cities', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('see', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('rebirth', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('hope', 'NN'),\n",
       " (',', ','),\n",
       " ('safety', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('opportunity', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Above', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('else', 'RB'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('keep', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('promises', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('American', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('[', 'NN'),\n",
       " ('Applause', 'NNP'),\n",
       " (']', 'NNP'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('little', 'RB'),\n",
       " ('over', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('month', 'NN'),\n",
       " ('since', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('Inauguration', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('update', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('Nation', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('progress', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('made', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('keeping', 'VBG'),\n",
       " ('those', 'DT'),\n",
       " ('promises', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Since', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('election', 'NN'),\n",
       " (',', ','),\n",
       " ('Ford', 'NNP'),\n",
       " (',', ','),\n",
       " ('Fiat', 'NNP'),\n",
       " ('Chrysler', 'NNP'),\n",
       " (',', ','),\n",
       " ('General', 'NNP'),\n",
       " ('Motors', 'NNPS'),\n",
       " (',', ','),\n",
       " ('Sprint', 'NNP'),\n",
       " (',', ','),\n",
       " ('Softbank', 'NNP'),\n",
       " (',', ','),\n",
       " ('Lockheed', 'NNP'),\n",
       " (',', ','),\n",
       " ('Intel', 'NNP'),\n",
       " (',', ','),\n",
       " ('Walmart', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('many', 'JJ'),\n",
       " ('others', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('announced', 'VBN'),\n",
       " ('that', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('invest', 'VB'),\n",
       " ('billions', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('billions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('dollars', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('and', 'CC'),\n",
       " ('will', 'MD'),\n",
       " ('create', 'VB'),\n",
       " ('tens', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('new', 'JJ'),\n",
       " ('American', 'JJ'),\n",
       " ('jobs', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('stock', 'NN'),\n",
       " ('market', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('gained', 'VBN'),\n",
       " ('almost', 'RB'),\n",
       " ('$', '$'),\n",
       " ('3', 'CD'),\n",
       " ('trillion', 'CD'),\n",
       " ('in', 'IN'),\n",
       " ('value', 'NN'),\n",
       " ('since', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('election', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('November', 'NNP'),\n",
       " ('8—a', 'CD'),\n",
       " ('record', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('saved', 'VBN'),\n",
       " ('taxpayers', 'NNS'),\n",
       " ('hundreds', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('millions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('dollars', 'NNS'),\n",
       " ('by', 'IN'),\n",
       " ('bringing', 'VBG'),\n",
       " ('down', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('price', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('fantastic—and', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('fantastic—new', 'JJ'),\n",
       " ('F-35', 'NNP'),\n",
       " ('jet', 'NN'),\n",
       " ('fighter', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('saving', 'VBG'),\n",
       " ('billions', 'NNS'),\n",
       " ('more', 'RBR'),\n",
       " ('on', 'IN'),\n",
       " ('contracts', 'NNS'),\n",
       " ('all', 'DT'),\n",
       " ('across', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('Government', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('placed', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('hiring', 'NN'),\n",
       " ('freeze', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('nonmilitary', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('nonessential', 'JJ'),\n",
       " ('Federal', 'NNP'),\n",
       " ('workers', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('begun', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('drain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('swamp', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('government', 'NN'),\n",
       " ('corruption', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('imposing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('5-year', 'JJ'),\n",
       " ('ban', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('lobbying', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('executive', 'JJ'),\n",
       " ('branch', 'NN'),\n",
       " ('officials', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('lifetime', 'NN'),\n",
       " ('ban—', 'NN'),\n",
       " ('[', 'NN'),\n",
       " ('applause', 'IN'),\n",
       " (']', 'NNP'),\n",
       " ('—thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('lifetime', 'JJ'),\n",
       " ('ban', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('becoming', 'VBG'),\n",
       " ('lobbyists', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('foreign', 'JJ'),\n",
       " ('government', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('undertaken', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('historic', 'JJ'),\n",
       " ('effort', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('massively', 'RB'),\n",
       " ('reduce', 'VB'),\n",
       " ('job-crushing', 'JJ'),\n",
       " ('regulations', 'NNS'),\n",
       " (',', ','),\n",
       " ('creating', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('deregulation', 'NN'),\n",
       " ('Task', 'NNP'),\n",
       " ('Force', 'NNP'),\n",
       " ('inside', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('Government', 'NNP'),\n",
       " ('agency', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('imposing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('rule', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('mandates', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('for', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('one', 'CD'),\n",
       " ('new', 'JJ'),\n",
       " ('regulation', 'NN'),\n",
       " (',', ','),\n",
       " ('two', 'CD'),\n",
       " ('old', 'JJ'),\n",
       " ('regulations', 'NNS'),\n",
       " ('must', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('eliminated', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('stop', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('regulations', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('threaten', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('future', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('livelihood', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('great', 'JJ'),\n",
       " ('coal', 'NN'),\n",
       " ('miners', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('cleared', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('construction', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Keystone', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Dakota', 'NNP'),\n",
       " ('Access', 'NNP'),\n",
       " ('pipelines', 'NNS'),\n",
       " (',', ','),\n",
       " ('thereby', 'RB'),\n",
       " ('creating', 'VBG'),\n",
       " ('tens', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('jobs', 'NNS'),\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "file = open(\"./datasets/trump.txt\", \"r\",encoding=\"utf-8\") \n",
    "trump = file.read()\n",
    "words = word_tokenize(trump)\n",
    "\n",
    "nltk.pos_tag(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3. Get the nouns in the last 10 sentences from Trump's speech and find the nouns divided by sentencens. Use SpaCy.\n",
    "\n",
    "Please use Python list features to get the last 10 sentences and display nouns from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  When we fulfill this vision, when we celebrate our 250 years of glorious freedom, we will look back on tonight as when this new chapter of American greatness began.\n",
      "Noun Phrases:  ['we', 'this vision', 'we', 'our 250 years', 'glorious freedom', 'we', 'tonight', 'this new chapter', 'American greatness']\n",
      "\n",
      ">  The time for small thinking is over.\n",
      "Noun Phrases:  ['The time', 'small thinking']\n",
      "\n",
      ">  The time for trivial fights is behind us.\n",
      "Noun Phrases:  ['The time', 'trivial fights', 'us']\n",
      "\n",
      ">  We just need the courage to share the dreams that fill our hearts, the bravery to express the hopes that stir our souls, and the confidence to turn those hopes and those dreams into action.\n",
      "\n",
      "\n",
      "Noun Phrases:  ['We', 'the courage', 'the dreams', 'that', 'our hearts', 'the bravery', 'the hopes', 'that', 'our souls', 'the confidence', 'those hopes', 'those dreams', 'action']\n",
      "\n",
      ">  From now on, America will be empowered by our aspirations, not burdened by our fears; inspired by the future, not bound by failures of the past; and guided by our vision, not blinded by our doubts.\n",
      "\n",
      "\n",
      "Noun Phrases:  ['America', 'our aspirations', 'our fears', 'the future', 'failures', 'the past', 'our vision', 'our doubts']\n",
      "\n",
      ">  I am asking all citizens to embrace this renewal of the American spirit.\n",
      "Noun Phrases:  ['I', 'all citizens', 'this renewal', 'the American spirit']\n",
      "\n",
      ">  I am asking all Members of Congress to join me in dreaming big and bold, and daring things for our country.\n",
      "Noun Phrases:  ['I', 'all Members', 'Congress', 'me', 'things', 'our country']\n",
      "\n",
      ">  I am asking everyone watching tonight to seize this moment.\n",
      "Noun Phrases:  ['I', 'everyone', 'this moment']\n",
      "\n",
      ">  Believe in yourselves, believe in your future, and believe, once more, in America.\n",
      "\n",
      "\n",
      "Noun Phrases:  ['yourselves', 'your future', 'America']\n",
      "\n",
      ">  Thank you, God bless you, and God bless the United States.\n",
      "Noun Phrases:  ['you', 'God', 'you', 'God', 'the United States']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "file = open(\"./datasets/trump.txt\", \"r\",encoding='utf-8') \n",
    "trump = file.read() \n",
    "file.close()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(trump)\n",
    "\n",
    "last10sentences = list(doc.sents)[-10:]\n",
    "\n",
    "for sentence in last10sentences:\n",
    "    print(\"> \", sentence)\n",
    "    noun_chunks = [chunk.text for chunk in sentence.noun_chunks]\n",
    "    print(\"Noun Phrases: \", noun_chunks)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4. Build your own Bag Of Words implementation using tokenizer created before \n",
    "\n",
    "You need to implement following methods:\n",
    "\n",
    "- ``fit_transform`` - gets a list of strings and returns matrix with it's BoW representation\n",
    "- ``get_features_names`` - returns list of words corresponding to columns in BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "class BagOfWords:\n",
    "    \"\"\"Basic BoW implementation.\"\"\"\n",
    "    \n",
    "    __nlp = spacy.load(\"en_core_web_sm\")\n",
    "    __bow_list = []\n",
    "    \n",
    "    # your code goes maybe also here    \n",
    "    \n",
    "    def fit_transform(self, corpus: list):\n",
    "        \"\"\"Transform list of strings into BoW array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus: List[str]\n",
    "                Corpus of texts to be transforrmed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "                Matrix representation of BoW\n",
    "\n",
    "        \"\"\"\n",
    "        # your code goes here        \n",
    "        return None\n",
    "      \n",
    "\n",
    "    def get_feature_names(self) -> list:\n",
    "        \"\"\"Return words corresponding to columns of matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "                Words being transformed by fit function\n",
    "\n",
    "        \"\"\"   \n",
    "        # your code goes here\n",
    "        return None\n",
    "\n",
    "corpus = [\n",
    "     'Bag Of Words is based on counting',\n",
    "     'words occurences throughout multiple documents.',\n",
    "     'This is the third document.',\n",
    "     'As you can see most of the words occur only once.',\n",
    "     'This gives us a pretty sparse matrix, see below. Really, see below',\n",
    "]    \n",
    "    \n",
    "vectorizer = BagOfWords()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)\n",
    "\n",
    "vectorizer.get_feature_names()\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5. Build a 5-gram model and clean up the results.\n",
    "\n",
    "There are three tasks to do:\n",
    "1. Use 5-gram model instead of 3.\n",
    "2. Change to capital letter each first letter of a sentence.\n",
    "3. Remove the whitespace between the last word in a sentence and . ! or ?.\n",
    "\n",
    "Hint: for 2. and 3. implement a function called ``clean_generated()`` that takes the generated text and fix both issues at once. It could be easier to fix the text after it's generated rather then doing some changes in the while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "\n",
    "wall_street = text7.tokens\n",
    "\n",
    "import re\n",
    "\n",
    "tokens = wall_street\n",
    "\n",
    "def cleanup():\n",
    "    compiled_pattern = re.compile(\"^[a-zA-Z0-9.!?]\")\n",
    "    clean = list(filter(compiled_pattern.match,tokens))\n",
    "    return clean\n",
    "\n",
    "tokens = cleanup()\n",
    "\n",
    "def build_ngrams():\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens)-N+1):\n",
    "        ngrams.append(tokens[i:i+N])\n",
    "    return ngrams\n",
    "\n",
    "def ngram_freqs(ngrams):\n",
    "    counts = {}\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        token_seq  = SEP.join(ngram[:-1])\n",
    "        last_token = ngram[-1]\n",
    "\n",
    "        if token_seq not in counts:\n",
    "            counts[token_seq] = {}\n",
    "\n",
    "        if last_token not in counts[token_seq]:\n",
    "            counts[token_seq][last_token] = 0\n",
    "\n",
    "        counts[token_seq][last_token] += 1;\n",
    "\n",
    "    return counts\n",
    "\n",
    "def next_word(text, N, counts):\n",
    "\n",
    "    token_seq = SEP.join(text.split()[-(N-1):]);\n",
    "    choices = counts[token_seq].items();\n",
    "\n",
    "    total = sum(weight for choice, weight in choices)\n",
    "    r = random.uniform(0, total)\n",
    "    upto = 0\n",
    "    for choice, weight in choices:\n",
    "        upto += weight;\n",
    "        if upto > r: return choice\n",
    "    assert False # should not reach here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "has been used mainly for travel and entertainment expenses . Phillip Riese an American Express executive vice president says 0 the promotion with Buick is his company first with an auto maker but hopefully will be the first of many in the company effort to promote its green card as the total car-care card . To that end American Express has been signing up gasoline companies car repair shops tire companies and car dealers to accept the card . Many auto dealers now let car buyers charge part or all of their purchase on the American Express green card . They have begun sending letters explaining the program which began Oct.\n",
      "\n",
      "After:\n",
      "Has been used mainly for travel and entertainment expenses. Phillip Riese an American Express executive vice president says 0 the promotion with Buick is his company first with an auto maker but hopefully will be the first of many in the company effort to promote its green card as the total car-care card. To that end American Express has been signing up gasoline companies car repair shops tire companies and car dealers to accept the card. Many auto dealers now let car buyers charge part or all of their purchase on the American Express green card. They have begun sending letters explaining the program which began Oct.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "def clean_generated(text):\n",
    "    result = text[0].upper() + text[1:] if text else text\n",
    "    result = re.compile(r'(?<=[.?!]\\s)(\\w)').sub(lambda x: x.group().capitalize(), result)\n",
    "    result = re.compile(r'\\s([.!?])').sub(r'\\1', result)\n",
    "    result = re.compile(r'\\s([,;])').sub(r'\\1', result)\n",
    "    result = re.compile(r'([.!?])([^\\s])').sub(r'\\1 \\2', result)\n",
    "    result = re.compile(r'\\b([A-Za-z])\\. (\\w)\\.').sub(r'\\1.\\2.', result)\n",
    "    result = re.compile(r'(\\d)\\. (\\d)').sub(r'\\1.\\2', result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "N=5 # fix it for other value of N\n",
    "\n",
    "SEP=\" \"\n",
    "\n",
    "sentence_count=5\n",
    "\n",
    "ngrams = build_ngrams()\n",
    "start_seq=\"We have\"\n",
    "\n",
    "counts = ngram_freqs(ngrams)\n",
    "\n",
    "if start_seq.lower() not in counts: \n",
    "    start_seq = random.choice(list(counts.keys()))\n",
    "generated = start_seq.lower()\n",
    "\n",
    "\n",
    "sentences = 0\n",
    "while sentences < sentence_count:\n",
    "    generated += SEP + next_word(generated, N, counts)\n",
    "    sentences += 1 if generated.endswith(('.','!', '?')) else 0\n",
    "\n",
    "# put your code here:\n",
    "\n",
    "print(f'Before:\\n{generated}\\n')   \n",
    "generated = clean_generated(generated)\n",
    "print(f'After:\\n{generated}\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
